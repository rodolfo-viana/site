<!doctype html><html class="dark light" lang=en><head><meta charset=UTF-8><meta content="IE=edge" http-equiv=X-UA-Compatible><meta content="width=device-width,initial-scale=1.0" name=viewport><meta content=https://rodolfoviana.com.br name=base><title>
         Gaussian processes with variational inference for binary classification
        
    </title><meta content="Gaussian processes with variational inference for binary classification" property=og:title><meta content="Edited version of an article written for the Machine Learning course, taught by Prof. Dr. João Paulo Papa, in the master's program of the Graduate Program in Computer Science at Unesp" property=og:description><meta content="Edited version of an article written for the Machine Learning course, taught by Prof. Dr. João Paulo Papa, in the master's program of the Graduate Program in Computer Science at Unesp" name=description><meta content=https://rodolfoviana.com.br/image.png property=og:image><meta content=image/png property=og:image:type><meta content=website property=og:type><meta content=https://rodolfoviana.com.br/en/projetos/gp-binario/ property=og:url><link href=/favicon.png rel=icon type=image/png><link href=https://rodolfoviana.com.br/fonts.css rel=stylesheet><script src=https://rodolfoviana.com.br/js/codeblock.js></script><script src=https://rodolfoviana.com.br/js/note.js></script><script>MathJax = {
          options: {enableMenu: false},
          loader: {load: ['[tex]/boldsymbol']},
          tex: {
            packages: {'[+]': ['boldsymbol']},
            inlineMath: [['\\(', '\\)']],
            displayMath: [['$$', '$$'], ['\\[', '\\]']],
            processEscapes: true,
            processEnvironments: true,
            }
        }</script><link title="rodolfo viana" href=https://rodolfoviana.com.br/rss.xml rel=alternate type=application/rss+xml><link href=https://rodolfoviana.com.br/theme/dark.css rel=stylesheet><script src=https://rodolfoviana.com.br/js/themetoggle.js></script><script>setTheme("dark");</script><link href=https://rodolfoviana.com.br/main.css media=screen rel=stylesheet><script src=https://rodolfoviana.com.br/js/mobile-menu.js></script><script src=https://rodolfoviana.com.br/js/d3.min.js></script><script async id=MathJax-script src=https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js></script><script src=https://rodolfoviana.com.br/js/geolocation.js></script><body><div class=content><header><div class=main><a href=https://rodolfoviana.com.br>rodolfo viana</a></div><button aria-label=Menu class=hamburger id=mobile-menu-button><span></span><span></span><span></span></button><nav id=nav-menu><a href=https://rodolfoviana.com.br/en/projetos style=margin-left:.5em>projects</a><a href=https://rodolfoviana.com.br/en/curriculo style=margin-left:.5em>résumé</a><a href=https://rodolfoviana.com.br/en/tags style=margin-left:.5em>tags</a><a onclick="switchLanguage('pt')" title="Voltar para Português" href=javascript:void(0) style=margin-left:.5em>PT</a></nav></header><main><article><div class=title><div class=page-header>Gaussian processes with variational inference for binary classification<span class=primary-color style=font-size:1.6em>.</span></div><div class=meta>Published: <time>12-03-2025</time><br><span class=tags-label>Tags:</span><span class=tags> <a class=post-tag href=https://rodolfoviana.com.br/en/tags/machine-learning/>machine learning</a>, <a class=post-tag href=https://rodolfoviana.com.br/en/tags/gaussian-processes/>gaussian processes</a>, <a class=post-tag href=https://rodolfoviana.com.br/en/tags/classification/>classification</a> </span></div></div><div class=toc-container><h1 class=toc-title>Table of Contents</h1><ul class=toc-list><li><a href=https://rodolfoviana.com.br/en/projetos/gp-binario/#introduction>Introduction</a><li><a href=https://rodolfoviana.com.br/en/projetos/gp-binario/#theoretical-foundation>Theoretical Foundation</a> <ul><li><a href=https://rodolfoviana.com.br/en/projetos/gp-binario/#gaussian-processes>Gaussian Processes</a><li><a href=https://rodolfoviana.com.br/en/projetos/gp-binario/#classification-with-gaussian-processes>Classification with Gaussian Processes</a><li><a href=https://rodolfoviana.com.br/en/projetos/gp-binario/#variational-inference>Variational Inference</a><li><a href=https://rodolfoviana.com.br/en/projetos/gp-binario/#variational-parametrization>Variational Parametrization</a></ul><li><a href=https://rodolfoviana.com.br/en/projetos/gp-binario/#methodology>Methodology</a> <ul><li><a href=https://rodolfoviana.com.br/en/projetos/gp-binario/#dataset>Dataset</a><li><a href=https://rodolfoviana.com.br/en/projetos/gp-binario/#evaluation-metrics>Evaluation Metrics</a></ul><li><a href=https://rodolfoviana.com.br/en/projetos/gp-binario/#experimental-results>Experimental Results</a> <ul><li><a href=https://rodolfoviana.com.br/en/projetos/gp-binario/#classification-performance>Classification Performance</a><li><a href=https://rodolfoviana.com.br/en/projetos/gp-binario/#probability-calibration>Probability Calibration</a><li><a href=https://rodolfoviana.com.br/en/projetos/gp-binario/#uncertainty-analysis>Uncertainty Analysis</a><li><a href=https://rodolfoviana.com.br/en/projetos/gp-binario/#training-convergence>Training Convergence</a></ul><li><a href=https://rodolfoviana.com.br/en/projetos/gp-binario/#discussion>Discussion</a><li><a href=https://rodolfoviana.com.br/en/projetos/gp-binario/#conclusion>Conclusion</a><li><a href=https://rodolfoviana.com.br/en/projetos/gp-binario/#references>References</a></ul></div><section class=body><h1 id=introduction>Introduction</h1><p>In classification problems, machine learning models are generally capable of presenting accurate point predictions; however, they often neglect the quantification of uncertainty inherent to such predictions<sup class=footnote-reference id=fr-1-1><a href=#fn-1>1</a></sup> <sup class=footnote-reference id=fr-2-1><a href=#fn-2>2</a></sup>. This limitation is particularly critical in real-world applications, where not only prediction accuracy but also reliability and uncertainty quantification are crucial for informed decision-making<sup class=footnote-reference id=fr-3-1><a href=#fn-3>3</a></sup>.<p>In this context, Gaussian Processes (GP) represent one of the most theoretically grounded tools for probabilistic machine learning<sup class=footnote-reference id=fr-4-1><a href=#fn-4>4</a></sup>. Unlike parametric methods that assume a specific functional form, GPs assign a probability distribution over functions, such that any finite subset of sample points follows a multivariate Gaussian distribution<sup class=footnote-reference id=fr-5-1><a href=#fn-5>5</a></sup>. They thus become suitable for constructing prediction intervals, as they delimit the expected range for the true value with a specific probability.<p>However, exact inference in GPs for classification is computationally intractable due to the non-conjugacy between the Bernoulli likelihood and the Gaussian prior<sup class=footnote-reference id=fr-6-1><a href=#fn-6>6</a></sup>. Variational Inference (VI) emerges as an elegant solution to this problem, transforming inference into an optimization problem by approximating the true posterior distribution with a tractable variational distribution<sup class=footnote-reference id=fr-7-1><a href=#fn-7>7</a></sup>. The variational ELBO (evidence lower bound) method maximizes a lower bound of the marginal evidence, ensuring that the approximation is as close as possible to the true distribution within the chosen variational family.<p>We present an implementation of Gaussian Processes with Variational Inference (GP-VI) for binary classification. The approach employs the Matérn kernel<sup class=footnote-reference id=fr-8-1><a href=#fn-8>8</a></sup> with \(\nu=1{.}5\) to capture complex structures in the data. We use all training points as inducing points (\(M = N\)), prioritizing model expressiveness over computational efficiency<sup class=footnote-reference id=fr-9-1><a href=#fn-9>9</a></sup>. Experiments conducted on the Wisconsin Breast Cancer dataset<sup class=footnote-reference id=fr-10-1><a href=#fn-10>10</a></sup> demonstrate not only high predictive accuracy but also the model's ability to provide uncertainty estimates.<h1 id=theoretical-foundation>Theoretical Foundation</h1><h2 id=gaussian-processes>Gaussian Processes</h2><p>A GP is a collection of random variables, any finite number of which has a joint Gaussian distribution<sup class=footnote-reference id=fr-4-2><a href=#fn-4>4</a></sup>. Formally, a GP is specified by its mean function \(m(\mathbf{x})\) and covariance function \(k(\mathbf{x}, \mathbf{x'})\), where<p>\[ \begin{aligned} m(\mathbf{x}) &= \mathbb{E}[f(\mathbf{x})] \\ k(\mathbf{x}, \mathbf{x'}) &= \mathbb{E}[(f(\mathbf{x}) - m(\mathbf{x}))(f(\mathbf{x'}) - m(\mathbf{x'}))]. \end{aligned} \]<p>Thus, we have \(f(\mathbf{x}) \sim \mathcal{GP}(m, k)\) to indicate that function \(f\) follows a GP with mean function \(m\) and covariance function \(k\).<p>Typically, \(m(\mathbf{x}) = 0\) is assumed for simplicity. The kernel function determines the smoothness properties and structural characteristics of functions sampled from the GP. In this work, we use the Matérn kernel<sup class=footnote-reference id=fr-8-2><a href=#fn-8>8</a></sup> with \(\nu = 1{.}5\), which produces once-differentiable functions, offering a balance between smoothness and flexibility.<p>Let \(r = \parallel\mathbf{x} - \mathbf{x}'\parallel\) be the Euclidean distance between two points, the Matérn kernel is defined as:<p>\[ k_{\text{Matérn}}(\mathbf{x}, \mathbf{x}') = \sigma^2 \left(1 + \frac{\sqrt{3}r}{\ell}\right) \exp\left(-\frac{\sqrt{3}r}{\ell}\right) \]<p>where \(\ell > 0\) is the length scale that controls the smoothness of the function, and \(\sigma^2 > 0\) is the scale variance that controls the amplitude of variations.<h2 id=classification-with-gaussian-processes>Classification with Gaussian Processes</h2><p>For binary classification, we model the latent function \(f(\mathbf{x})\) as a GP and connect this function to binary observations \(y \in {0,1}\) through a likelihood function. Using the Bernoulli likelihood<sup class=footnote-reference id=fr-5-2><a href=#fn-5>5</a></sup>:<p>\[ p(y \mid \mathbf{x}) = \text{Bernoulli}(\sigma(f(\mathbf{x}))) \]<p>where \(\sigma(\cdot)\) is the logistic function. The objective is to compute the posterior distribution \(p(f \mid \mathcal{D})\) given the dataset \(\mathcal{D} = {(\mathbf{x}_i, y_i)}_{i=1}^N\).<h2 id=variational-inference>Variational Inference</h2><p>The exact posterior \(p(f \mid \mathcal{D})\) is intractable due to the non-conjugacy between the Gaussian prior and the Bernoulli likelihood. Variational Inference approximates the true posterior with a tractable variational distribution \(q(f)\), minimizing the Kullback-Leibler divergence<sup class=footnote-reference id=fr-11-1><a href=#fn-11>11</a></sup>:<p>\[ \mathcal{L}_{\text{ELBO}} = \sum_{i=1}^N \mathbb{E}_{q(f_i)}[\log p(y_i \mid f_i)] - \text{KL}(q(f) \parallel p(f)) \]<p>Training minimizes \(- \mathcal{L}_{\text{ELBO}}\), i.e., maximizes the ELBO.<h2 id=variational-parametrization>Variational Parametrization</h2><p>Variational inference approximates the intractable posterior through a variational distribution \(q(\mathbf{u})\) over the function values at inducing points \(\mathbf{u} = f(\mathbf{Z})\), where \(\mathbf{Z}\) represents the set of inducing points<sup class=footnote-reference id=fr-6-2><a href=#fn-6>6</a></sup>. The variational distribution is parametrized as a Gaussian \(q(\mathbf{u}) = \mathcal{N}(\mathbf{m}, \mathbf{S})\), where \(\mathbf{m}\) is the mean vector and \(\mathbf{S}\) is the covariance matrix.<p>To ensure that \(\mathbf{S}\) remains positive definite during optimization, we use the Cholesky parametrization:<p>\[ q(\mathbf{u}) = \mathcal{N}(\mathbf{m}, \mathbf{S}), \quad \mathbf{S} = \mathbf{L}\mathbf{L}^T \]<p>where \(\mathbf{L}\) is a lower triangular matrix. The variational parameters \(\mathbf{m}\) and \(\mathbf{L}\) are learned through ELBO maximization.<h1 id=methodology>Methodology</h1><p>We implemented a variational GP model whose architecture consists of: (i) a mean module that uses a constant mean \(m(\mathbf{x}) = c\); (ii) a covariance module based on scaled kernel \(k(\mathbf{x}, \mathbf{x}') = \sigma^2 k_{\text{Matérn}}(\mathbf{x}, \mathbf{x}')\); (iii) a variational distribution \(q(\mathbf{u})\) parametrized via Cholesky decomposition, where we use all \(N\) training points as inducing points (\(M = N = 455\)); and (iv) a Bernoulli likelihood for binary classification.<p>This choice of \(M = N\) eliminates the sparse approximation, resulting in a more expressive model at the cost of greater computational complexity. For larger datasets, a strategy with \(M \ll N\) would be necessary for scalability<sup class=footnote-reference id=fr-9-2><a href=#fn-9>9</a></sup>.<p>Training is performed by maximizing the ELBO through gradient-based optimization. The optimization process simultaneously updates: (i) kernel parameters (\(\ell\), \(\sigma^2\)); (ii) variational parameters (\(\mathbf{m}\), \(\mathbf{L}\)); and (iii) inducing point locations \(\mathbf{Z}\), when enabled.<p>To ensure numerical stability during training, we use the Cholesky parametrization for the variational covariance matrix. Additionally, we add a jitter term (\(10^{-6}\)) to the diagonal of covariance matrices when necessary, and gradients are computed through automatic differentiation, minimizing numerical errors.<p>During inference, for a test point \(\mathbf{x}_*\), we compute the predictive distribution:<p>\[ p(f_{*} \mid \mathcal{D}, \mathbf{x}_{*}) \approx \int p(f_{*} \mid \mathbf{u}) q(\mathbf{u}) , d\mathbf{u} \]<p>This is a Gaussian distribution with mean \(\mu_*\) and variance \(\sigma_{*}^2\). The probability of the positive class is obtained by propagating this distribution through the likelihood:<p>\[ p(y_{*}=1 \mid \mathcal{D}, \mathbf{x}_{*}) = \mathbb{E}_{f_{*}\sim\mathcal{N}(\mu_*,\sigma_{*}^2})\big[\sigma(f_*)\big] \]<p>Predictive uncertainty is quantified by the standard deviation \(\sigma_*\) in the latent space, which reflects both epistemic uncertainty and data randomness.<h2 id=dataset>Dataset</h2><p>We use the Wisconsin Breast Cancer dataset<sup class=footnote-reference id=fr-10-2><a href=#fn-10>10</a></sup> <sup class=footnote-reference id=fr-12-1><a href=#fn-12>12</a></sup>. This dataset contains 569 samples with 30 features calculated from digitized images of breast mass aspirates, with the task of classifying tumors as malignant (1) or benign (0).<p>The data was split into 80% training and 20% testing using stratification to maintain class proportions. All features were standardized on the training set.<h2 id=evaluation-metrics>Evaluation Metrics</h2><p>We evaluate the model using a comprehensive set of metrics. Classification metrics include accuracy,<p>\[ \text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}, \]<p>F1-Score, area under the ROC curve \(\text{AUC-ROC} \in [0,1]\) and area under the Precision-Recall curve \(\text{AUPRC} \in [0,1]\).<p>Calibration metrics comprise the Brier score:<p>\[ \text{BS} = \frac{1}{N}\sum_{i=1}^{N}(p_i - y_i)^2, \]<p>log loss, and expected calibration error (ECE).<h1 id=experimental-results>Experimental Results</h1><h2 id=classification-performance>Classification Performance</h2><p>The model achieved excellent predictive performance, with accuracy above 96% and AUC-ROC of 99.34%, indicating high discriminative capacity. The F1-Score of 97.22% demonstrates balance between precision and sensitivity. The AUPRC of 99.58% confirms robust performance even considering different decision thresholds.<table style="border-collapse:collapse;margin:0 auto"><caption style="caption-side:top;padding:8px 0;font-weight:600">GP-VI Model Results on Wisconsin Breast Cancer</caption><thead><tr><th style="text-align:left;border:1px solid #ccc;padding:8px">Metric<th style="text-align:left;border:1px solid #ccc;padding:8px">Value<tbody><tr><td style="border:1px solid #ccc;padding:8px">Accuracy<td style="border:1px solid #ccc;padding:8px">96.49%<tr><td style="border:1px solid #ccc;padding:8px">F1-Score<td style="border:1px solid #ccc;padding:8px">97.22%<tr><td style="border:1px solid #ccc;padding:8px">AUC-ROC<td style="border:1px solid #ccc;padding:8px">99.34%<tr><td style="border:1px solid #ccc;padding:8px">AUPRC<td style="border:1px solid #ccc;padding:8px">99.58%<tr><td colspan=2 style=border:0;padding:0><hr style="border:none;border-top:1px solid #ccc;margin:0"><tr><td style="border:1px solid #ccc;padding:8px">Brier Score<td style="border:1px solid #ccc;padding:8px">0.0355<tr><td style="border:1px solid #ccc;padding:8px">Log Loss<td style="border:1px solid #ccc;padding:8px">0.1397<tr><td style="border:1px solid #ccc;padding:8px">ECE<td style="border:1px solid #ccc;padding:8px">0.3771<tr><td colspan=2 style=border:0;padding:0><hr style="border:none;border-top:1px solid #ccc;margin:0"><tr><td style="border:1px solid #ccc;padding:8px">Training Time<td style="border:1px solid #ccc;padding:8px">8.19s</table><p>The confusion matrix reveals only 4 incorrect predictions out of 114 test samples.<figure style="width:60%;max-width:60%;height:auto;margin:0 auto;display:block"><img style="background-color:#fff;border:5px solid #ef5350" src=./matriz.png><figcaption style=color:#555;margin-top:1px;font-size:.8em;line-height:1.5>Confusion matrix</figcaption></figure><h2 id=probability-calibration>Probability Calibration</h2><p>The Brier score of 0.0355 indicates excellent quality of predictive probabilities, with low discrepancy between predicted probabilities and real observations. The log loss of 0.1397 confirms that the model assigns high probability to the correct classes.<p>However, the ECE of 0.3771 reveals a significant calibration problem<sup class=footnote-reference id=fr-13-1><a href=#fn-13>13</a></sup>. ECE values above 0.1 indicate poor calibration, and an ECE above 0.3 suggests that the model is systematically over or under-confident in its predictions. This discrepancy between the low Brier score and high ECE can be explained by the nature of each metric: the Brier score is a global measure sensitive to overall probability accuracy, while ECE specifically evaluates whether calibrated probabilities reflect the actual frequency of correct predictions within each confidence bin.<p>The model's high precision (96.49% accuracy) combined with poor calibration suggests that the model is overly confident in its predictions, a common phenomenon in deep learning models and variational methods<sup class=footnote-reference id=fr-13-2><a href=#fn-13>13</a></sup>. Post-hoc recalibration techniques, such as temperature scaling or isotonic regression, could significantly improve ECE without compromising predictive accuracy.<h2 id=uncertainty-analysis>Uncertainty Analysis</h2><p>The table below presents predictive uncertainty statistics, revealing an apparently counter-intuitive pattern: the average uncertainty of correct predictions (\(1{.}024\pm0{.}156\)) is slightly higher than that of incorrect predictions (\(0{.}915\pm0{.}033\)).<table style="border-collapse:collapse;margin:0 auto"><caption style="caption-side:top;padding:8px 0;font-weight:600">Predictive Uncertainty Statistics</caption><thead><tr><th style="text-align:left;border:1px solid #ccc;padding:8px">Statistic<th style="text-align:left;border:1px solid #ccc;padding:8px">Value<tbody><tr><td style="border:1px solid #ccc;padding:8px">Global Mean Uncertainty<td style="border:1px solid #ccc;padding:8px">1.020<tr><td style="border:1px solid #ccc;padding:8px">Median Uncertainty<td style="border:1px solid #ccc;padding:8px">1.004<tr><td style="border:1px solid #ccc;padding:8px">Uncertainty Standard Deviation<td style="border:1px solid #ccc;padding:8px">0.154<tr><td style="border:1px solid #ccc;padding:8px">Q1<td style="border:1px solid #ccc;padding:8px">0.906<tr><td style="border:1px solid #ccc;padding:8px">Q3<td style="border:1px solid #ccc;padding:8px">1.134<tr><td style="border:1px solid #ccc;padding:8px">IQR<td style="border:1px solid #ccc;padding:8px">0.228<tr><td style="border:1px solid #ccc;padding:8px">Minimum Uncertainty<td style="border:1px solid #ccc;padding:8px">0.736<tr><td style="border:1px solid #ccc;padding:8px">Maximum Uncertainty<td style="border:1px solid #ccc;padding:8px">1.357<tr><td style="border:1px solid #ccc;padding:8px">Mean Uncertainty (Correct Predictions)<td style="border:1px solid #ccc;padding:8px">1.024 ± 0.156<tr><td style="border:1px solid #ccc;padding:8px">Mean Uncertainty (Incorrect Predictions)<td style="border:1px solid #ccc;padding:8px">0.915 ± 0.033<tr><td style="border:1px solid #ccc;padding:8px">Two-tailed t-test<td style="border:1px solid #ccc;padding:8px">t = 1.39, p = 0.168</table><p>To assess the statistical significance of this difference, we performed an independent t-test comparing the uncertainty distributions. The test resulted in \(t = 1{.}39\) with \(p = 0{.}168\), indicating that there is no statistical evidence of a significant difference between the uncertainties of correct and incorrect predictions at the 5% significance level.<p>This result, although apparently counter-intuitive, can be explained by several factors. First, the reduced number of incorrect predictions (\(n = 4\)) limits the statistical power of the test. Second, incorrect predictions may occur in high-confidence regions due to outliers, label ambiguity, or noise in the data. Third, the model may exhibit high uncertainty in regions close to the decision boundary, where it still classifies correctly due to the 0.5 threshold. Finally, uncertainty in the latent space captures both epistemic uncertainty (lack of knowledge about the true function) and aleatoric uncertainty (intrinsic noise), making the relationship between uncertainty and prediction correctness inherently complex and not necessarily monotonic.<h2 id=training-convergence>Training Convergence</h2><p>The ELBO loss converged smoothly from approximately 0.79 at epoch 10 to 0.202 at the final epoch, indicating stable optimization without significant oscillations. The total training time was 8.19 seconds, demonstrating the computational efficiency of the variational approach even when using all training points as inducers.<h1 id=discussion>Discussion</h1><p>The results demonstrate that Gaussian Processes with Variational Inference constitute a promising approach for binary classification with uncertainty quantification. The model showed high predictive accuracy on the Wisconsin Breast Cancer dataset, with metrics above 96% in accuracy, F1-Score, AUC-ROC, and AUPRC.<p>The Brier score (0.0355) and log loss (0.1397) indicate good overall quality of predictive probabilities. However, the elevated ECE (0.3771) reveals a significant calibration problem, suggesting that the model is overly confident in its predictions. This is an important result that highlights the need for post-hoc recalibration techniques in applications where well-calibrated probabilities are critical.<p>The uncertainty analysis revealed that there is no statistically significant difference between the uncertainties of correct and incorrect predictions, indicating that the relationship between epistemic uncertainty and accuracy is more complex than initially expected. This result underscores the importance of rigorous statistical analyses when interpreting uncertainty estimates.<p>The variational approach with ELBO allows efficient training, with a training time of only 8.19 seconds even when using all 455 training points as inducers. This efficiency, however, does not scale well for much larger datasets.<h1 id=conclusion>Conclusion</h1><p>This work presented an implementation of Gaussian Processes with Variational Inference for binary classification, evaluated on the Wisconsin Breast Cancer dataset. The results demonstrate promising performance, with 96.49% accuracy and 99.34% AUC-ROC.<p>We identified that, despite the low Brier score, the model presents poor calibration according to ECE, revealing overconfidence in predictions. This result highlights the risk of evaluating a single calibration metric.<p>The statistical analysis of uncertainty revealed that there is no evidence of a significant difference between the uncertainties of correct and incorrect predictions (\(p = 0{.}168\)). This result emphasizes the complexity of the relationship between epistemic uncertainty and predictive performance, suggesting that simplistic interpretations of uncertainty can be misleading.<p>We recognize important limitations of this study. First, the results are based on a single small dataset, limiting the generalization of conclusions. Second, the choice of $M = N$ eliminates the scalability benefits of sparse approximation, making the approach impractical for datasets with tens of thousands of samples. Third, the elevated ECE indicates that the model requires recalibration before being used in critical applications where reliable probability estimates are essential.<p>Future work should focus on validation across multiple datasets from different domains and sizes, and systematic comparison with other probabilistic methods, such as Bayesian Dropout and Deep Ensembles. Additionally, one could investigate methods for automatic selection of inducing points for scalability (\(M \ll N\)) and application of recalibration techniques to improve ECE. Finally, there is room for exploration of different kernels or combinations.<h1 id=references>References</h1><section class=footnotes><ol class=footnotes-list><li id=fn-1><p>Y. Gal, "Uncertainty in Deep Learning", PhD Thesis, University of Cambridge, 2016. <a href=#fr-1-1>↩</a></p><li id=fn-2><p>V. Kuleshov, N. Fenner, and S. Ermon, "Accurate uncertainties for deep learning using calibrated regression", in <em>Proceedings of the 35th International Conference on Machine Learning</em>, vol. 80. PMLR, 2018, pp. 2796-2804. <a href=#fr-2-1>↩</a></p><li id=fn-3><p>E. Hüllermeier and W. Waegeman, "Aleatoric and epistemic uncertainty in machine learning: an introduction to concepts and methods", in <em>Machine Learning</em>, vol. 110. Springer, 2021, pp. 457-506. <a href=#fr-3-1>↩</a></p><li id=fn-4><p>C. E. Rasmussen and C. K. I. Williams, <em>Gaussian Processes for Machine Learning</em>. MIT Press, 2006. <a href=#fr-4-1>↩</a> <a href=#fr-4-2>↩2</a></p><li id=fn-5><p>K. P. Murphy, <em>Machine Learning: A Probabilistic Perspective</em>. MIT Press, 2012. <a href=#fr-5-1>↩</a> <a href=#fr-5-2>↩2</a></p><li id=fn-6><p>J. Hensman, A. Matthews, and Z. Ghahramani, "Scalable Variational Gaussian Process Classification", in <em>Proceedings of the 18th International Conference on Artificial Intelligence and Statistics</em>, vol. 38. PMLR, 2015, pp. 351-360. <a href=#fr-6-1>↩</a> <a href=#fr-6-2>↩2</a></p><li id=fn-7><p>D. M. Blei, A. Kucukelbir, and J. D. McAuliffe, "Variational Inference: A Review for Statisticians", in <em>Journal of the American Statistical Association</em>, vol. 112, no. 518. Taylor & Francis, 2017, pp. 859-877. <a href=#fr-7-1>↩</a></p><li id=fn-8><p>B. Matérn, <em>Spatial Variation</em>, vol. 36. Springer-Verlag, 1986. (Orig. 1960). <a href=#fr-8-1>↩</a> <a href=#fr-8-2>↩2</a></p><li id=fn-9><p>M. K. Titsias, "Variational Learning of Inducing Variables in Sparse Gaussian Processes", in <em>Proceedings of the 12th International Conference on Artificial Intelligence and Statistics</em>, vol. 5. PMLR, 2009, pp. 567-574. <a href=#fr-9-1>↩</a> <a href=#fr-9-2>↩2</a></p><li id=fn-10><p>W. Wolberg, O. Mangasarian, N. Street and W. Street, "Breast Cancer Wisconsin (Diagnostic) [Data Set]", UCI Machine Learning Repository [Online], 1993. Available at https://archive.ics.uci.edu/. Accessed November 2, 2025. <a href=#fr-10-1>↩</a> <a href=#fr-10-2>↩2</a></p><li id=fn-11><p>S. Kullback and R. A. Leibler, "On information and sufficiency", in <em>The Annals of Mathematical Statistics</em>, vol. 22, no. 1. Institute of Mathematical Statistics, 1951, pp. 79-86. <a href=#fr-11-1>↩</a></p><li id=fn-12><p>W. H. Wolberg and O. L. Mangasarian, "Multisurface Method of Pattern Separation for Medical Diagnosis Applied to Breast Cytology", in <em>Proceedings of the National Academy of Sciences</em>, vol. 87, no. 23. National Academy of Sciences, 1990, pp. 9193-9196. <a href=#fr-12-1>↩</a></p><li id=fn-13><p>C. Guo, G. Pleiss, Y. Sun, and K. Q. Weinberger, "On Calibration of Modern Neural Networks", in <em>Proceedings of the 34th International Conference on Machine Learning</em>, vol. 70. PMLR, 2017, pp. 1321-1330. <a href=#fr-13-1>↩</a> <a href=#fr-13-2>↩2</a></p></ol></section></section></article></main><footer class=footer><div class=footer-content><div class=footer-left>© 2026 Rodolfo Viana</div><div class=footer-right>Made with <a href=https://www.getzola.org/ rel=noopener target=_blank>Zola</a>, <a href=https://github.com/not-matthias/apollo rel=noopener target=_blank>Apollo</a></div></div></footer></div>