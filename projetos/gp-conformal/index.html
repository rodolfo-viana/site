<!doctype html><html class="dark light" lang=pt><head><meta charset=UTF-8><meta content="IE=edge" http-equiv=X-UA-Compatible><meta content="width=device-width,initial-scale=1.0" name=viewport><meta content=https://rodolfoviana.com.br name=base><title>
         Quantificação de incertezas com processos gaussianos e previsão conformal
        
    </title><meta content="Quantificação de incertezas com processos gaussianos e previsão conformal" property=og:title><meta content="Versão editada de artigo escrito para a disciplina Redes Neurais Artificiais, do Prof. Dr. Lucas Ribas, no curso de mestrado do Programa de Pós-Graduação em Ciência da Computação da Unesp" property=og:description><meta content="Versão editada de artigo escrito para a disciplina Redes Neurais Artificiais, do Prof. Dr. Lucas Ribas, no curso de mestrado do Programa de Pós-Graduação em Ciência da Computação da Unesp" name=description><meta content=https://rodolfoviana.com.br/image.png property=og:image><meta content=image/png property=og:image:type><meta content=website property=og:type><meta content=https://rodolfoviana.com.br/projetos/gp-conformal/ property=og:url><link href=/favicon.png rel=icon type=image/png><link href=https://rodolfoviana.com.br/fonts.css rel=stylesheet><script src=https://rodolfoviana.com.br/js/codeblock.js></script><script src=https://rodolfoviana.com.br/js/note.js></script><script>MathJax = {
          options: {enableMenu: false},
          loader: {load: ['[tex]/boldsymbol']},
          tex: {
            packages: {'[+]': ['boldsymbol']},
            inlineMath: [['\\(', '\\)']],
            displayMath: [['$$', '$$'], ['\\[', '\\]']],
            processEscapes: true,
            processEnvironments: true,
            }
        }</script><link title="rodolfo viana" href=https://rodolfoviana.com.br/rss.xml rel=alternate type=application/rss+xml><link href=https://rodolfoviana.com.br/theme/dark.css rel=stylesheet><script src=https://rodolfoviana.com.br/js/themetoggle.js></script><script>setTheme("dark");</script><link href=https://rodolfoviana.com.br/main.css media=screen rel=stylesheet><script src=https://rodolfoviana.com.br/js/mobile-menu.js></script><script src=https://rodolfoviana.com.br/js/d3.min.js></script><script async id=MathJax-script src=https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js></script><script src=https://rodolfoviana.com.br/js/geolocation.js></script><body><div class=content><header><div class=main><a href=https://rodolfoviana.com.br>rodolfo viana</a></div><button aria-label=Menu class=hamburger id=mobile-menu-button><span></span><span></span><span></span></button><nav id=nav-menu><a href=https://rodolfoviana.com.br/projetos style=margin-left:.5em>projetos</a><a href=https://rodolfoviana.com.br/curriculo style=margin-left:.5em>cv</a><a href=https://rodolfoviana.com.br/tags style=margin-left:.5em>tags</a><a onclick="switchLanguage('en')" title="Switch to English" href=javascript:void(0) style=margin-left:.5em>EN</a></nav></header><main><article><div class=title><div class=page-header>Quantificação de incertezas com processos gaussianos e previsão conformal<span class=primary-color style=font-size:1.6em>.</span></div><div class=meta>Publicação: <time>17-06-2025</time><br><span class=tags-label>Tags:</span><span class=tags> <a class=post-tag href=https://rodolfoviana.com.br/tags/aprendizado-de-maquina/>aprendizado de máquina</a>, <a class=post-tag href=https://rodolfoviana.com.br/tags/processos-gaussianos/>processos gaussianos</a>, <a class=post-tag href=https://rodolfoviana.com.br/tags/redes-neurais/>redes neurais</a> </span></div></div><div class=toc-container><h1 class=toc-title>Sumário</h1><ul class=toc-list><li><a href=https://rodolfoviana.com.br/projetos/gp-conformal/#introducao>Introdução</a><li><a href=https://rodolfoviana.com.br/projetos/gp-conformal/#metodologia>Metodologia</a> <ul><li><a href=https://rodolfoviana.com.br/projetos/gp-conformal/#processos-gaussianos-exatos>Processos Gaussianos Exatos</a><li><a href=https://rodolfoviana.com.br/projetos/gp-conformal/#processo-gaussiano-variacional-estocastico>Processo Gaussiano Variacional Estocástico</a><li><a href=https://rodolfoviana.com.br/projetos/gp-conformal/#predicao-conformal>Predição Conformal</a><li><a href=https://rodolfoviana.com.br/projetos/gp-conformal/#execucao-de-testes>Execução de Testes</a></ul><li><a href=https://rodolfoviana.com.br/projetos/gp-conformal/#resultados>Resultados</a><li><a href=https://rodolfoviana.com.br/projetos/gp-conformal/#conclusao>Conclusão</a><li><a href=https://rodolfoviana.com.br/projetos/gp-conformal/#referencias>Referências</a></ul></div><section class=body><h1 id=introducao>Introdução</h1><p>Em problemas de regressão, modelos de aprendizado de máquina geralmente são capazes de apresentar predições pontuais com rigor; contudo, não raro negligenciam a quantificação da incerteza inerente a tais predições<sup class=footnote-reference id=fr-1-1><a href=#fn-1>1</a></sup> <sup class=footnote-reference id=fr-2-1><a href=#fn-2>2</a></sup>. Essa limitação é particularmente crítica em aplicações reais, onde não apenas a precisão da previsão, mas também a confiabilidade e a quantificação da incerteza são cruciais para a tomada de decisões informadas<sup class=footnote-reference id=fr-3-1><a href=#fn-3>3</a></sup>.<p>Neste cenário, modelos baseados em processos gaussianos (GP) destacam-se como uma abordagem robusta<sup class=footnote-reference id=fr-4-1><a href=#fn-4>4</a></sup>. São capazes de fornecer não apenas predições pontuais, mas também distribuições de probabilidade completas para as predições<sup class=footnote-reference id=fr-5-1><a href=#fn-5>5</a></sup>, permitindos capturar tanto a incerteza epistêmica quanto a incerteza aleatória. A incerteza epistêmica refere-se à incerteza no modelo devido à falta de dados ou conhecimento, podendo ser reduzida com mais observações, enquanto a incerteza aleatória é inerente ao processo de geração dos dados e não pode ser reduzida, representando o ruído natural do sistema<sup class=footnote-reference id=fr-6-1><a href=#fn-6>6</a></sup>.<p>Processos gaussianos atribuem distribuição probabilística a funções, de modo que qualquer subconjunto finito de pontos amostrais obedece a uma distribuição gaussiana multivariada<sup class=footnote-reference id=fr-5-2><a href=#fn-5>5</a></sup>. Tornam-se, assim, adequados para construir intervalos de predição, pois delimitam a faixa esperada para o valor real com uma probabilidade específica<sup class=footnote-reference id=fr-4-2><a href=#fn-4>4</a></sup>.<p>Na prática, contudo, intervalos extraídos diretamente de um GP podem não entregar a cobertura nominal desejada<sup class=footnote-reference id=fr-7-1><a href=#fn-7>7</a></sup>. É neste contexto que a predição conformal se apresenta como uma abordagem complementar<sup class=footnote-reference id=fr-8-1><a href=#fn-8>8</a></sup> <sup class=footnote-reference id=fr-9-1><a href=#fn-9>9</a></sup>. Trata-se de uma técnica estatística que permite calibrar os intervalos de predição para garantir propriedades teóricas de cobertura, independentemente da distribuição subjacente dos dados ou da adequação do modelo<sup class=footnote-reference id=fr-10-1><a href=#fn-10>10</a></sup> <sup class=footnote-reference id=fr-11-1><a href=#fn-11>11</a></sup>.<p>Uma configuração de modelo que integre GP e predição conformal torna-se uma abordagem promissora para a construção de intervalos que são simultaneamente informativos e confiáveis. Neste trabalho, investigamos essa configuração: implementamos o Processo Gaussiano aprimorado por rede neural (NE-GP, de <em>Neural-Enhanced Gaussian Process</em>) e o Processo Gaussiano Variacional Estocástico aprimorado por rede neural (NE-SVGP, de <em>Neural-Enhanced Stochastic Variational Gaussian Process</em>). Para cada um desses modelos, comparamos o desempenho dos intervalos de predição antes e após a aplicação do método conformal, em termos de cobertura e largura dos intervalos.<h1 id=metodologia>Metodologia</h1><p>A implementação dos modelos propostos neste trabalho segue uma arquitetura híbrida que combina redes neurais com processos gaussianos, criando os modelos NE-GP e NE-SVGP. Esta abordagem utiliza as bibliotecas PyTorch e GPyTorch para implementar uma arquitetura de duas etapas: extração de características neurais seguida de modelagem probabilística gaussiana.<p>A arquitetura híbrida consiste em dois componentes principais integrados: um extrator de características baseado em perceptron multicamadas (MLP) que transforma os dados de entrada em representações de maior nível, e um GP que opera sobre essas características extraídas para fornecer predições de intervalos. O MLP é estruturado com três camadas totalmente conectadas: uma camada de entrada que recebe as características originais dos dados, duas camadas ocultas com 64 neurônios cada, aplicando funções de ativação ReLU e <em>dropout</em> de 0,1 para regularização, e uma camada de saída com 32 neurônios que produz as características refinadas.<p>O GP subsequente opera sobre essas características extraídas (\(\mathbf{z}\)), utilizando uma função de base radial para modelar as correlações no espaço de características transformado. A escolha do kernel <em>Radial Basis Function</em> deve-se à sua capacidade de capturar relações não-lineares suaves entre variáveis, sendo adequado para a maioria dos problemas de regressão. Outras opções como kernels periódicos ou Matérn poderiam ser usadas para capturar padrões específicos como sazonalidade ou diferentes graus de suavidade.<p>O treinamento conjunto otimiza simultaneamente os parâmetros do MLP (\(\mathbf{W}_i, \mathbf{b}_i\)) e os hiperparâmetros do GP (\(\boldsymbol{\theta}_{GP}\)) através de gradiente descendente<p>\[ \begin{aligned} \mathcal{L}(\mathbf{W}, \mathbf{b}, \boldsymbol{\theta}_{GP}) &= -\log p(\mathbf{y}\mid\text{MLP}(\mathbf{X}), \boldsymbol{\theta}_{GP}) \\ \boldsymbol{\phi}_{t+1} &= \boldsymbol{\phi}_t - \eta \nabla_{\boldsymbol{\phi}} \mathcal{L}(\boldsymbol{\phi}_t), \end{aligned} \]<p>onde \(\boldsymbol{\phi} = \{\mathbf{W}, \mathbf{b}, \boldsymbol{\theta}_{GP}\}\) representa todos os parâmetros treináveis do modelo híbrido.<p>Esta arquitetura híbrida une o poder das redes neurais na extração de características complexas com a precisão dos GPs na quantificação de incerteza.<h2 id=processos-gaussianos-exatos>Processos Gaussianos Exatos</h2><p>Um GP é uma família de variáveis aleatórias tal que qualquer subconjunto finito segue uma distribuição gaussiana multivariada<sup class=footnote-reference id=fr-4-3><a href=#fn-4>4</a></sup> <sup class=footnote-reference id=fr-5-3><a href=#fn-5>5</a></sup>. Tal propriedade garante exatidão à inferência bayesiana sem a necessidade de recorrer a aproximações numéricas — difere, por exemplo, de redes neurais bayesianas, que precisam de amostragem Monte Carlo ou métodos variacionais.<p>Formalmente, um GP é especificado por sua função de média \(m(\mathbf{x})\) e função de covariância \(k(\mathbf{x}, \mathbf{x'})\), onde<p>\[ \begin{aligned} m(\mathbf{x}) &= \mathbb{E}[f(\mathbf{x})] \\ k(\mathbf{x}, \mathbf{x'}) &= \mathbb{E}[(f(\mathbf{x}) - m(\mathbf{x}))(f(\mathbf{x'}) - m(\mathbf{x'}))] \end{aligned} \]<p>Assim, temos \(f(\mathbf{x}) \sim \mathcal{GP}(m, k)\) para indicar que a função \(f\) segue um GP com função de média \(m\) e função de covariância \(k\).<p>No problema de regressão, dada uma amostra de treinamento \(\mathcal{D} = {(\mathbf{x}_i, y_i)}_{i=1}^{n}\) e assumindo ruído gaussiano homoscedático \(y_i = f(\mathbf{x}_i) + \varepsilon_i\), onde \(\varepsilon_i \sim \mathcal{N}(0, \sigma^2)\), a posteriori para um novo ponto \(\mathbf{x}_*\) é gaussiana com parâmetros<p>\[ \begin{aligned} \mu(\mathbf{x}_*) &= \mathbf{k}_*^\top(\mathbf{K} + \sigma^2\mathbf{I})^{-1}\mathbf{y} \\ \sigma^2(\mathbf{x}_*) &= k(\mathbf{x}_*, \mathbf{x}_*) - \mathbf{k}_*^\top(\mathbf{K} + \sigma^2\mathbf{I})^{-1}\mathbf{k}_* \end{aligned} \]<p>onde \(\mathbf{K}\) é a matriz de covariância entre os pontos de treinamento e \(\mathbf{k}_*\) contém as covariâncias entre \(\mathbf{x}_*\) e cada \(\mathbf{x}_i\).<p>Neste trabalho, para obtermos funções-amostra suaves e isotrópicas, utilizamos a função de base radial para cálculo da covariância, definido como<p>\[ k(\mathbf{x}, \mathbf{x'}) = \sigma_f^2 \exp\left(-\frac{||\mathbf{x} - \mathbf{x'}||^2}{{{2l^2}}}\right) \]<p>onde \(\sigma_f^2\) é a variância do sinal e \(l\) é o comprimento de escala, que controla a suavidade da função. Estes hiperparâmetros são otimizados maximizando a log-verossimilhança marginal dos dados de treinamento. A log-verossimilhança marginal é obtida integrando sobre a função latente \(f\), resultando em<p>\[ \log p(\mathbf{y}|\mathbf{X}, \boldsymbol{\theta}) = -\frac{1}{2}\mathbf{y}^\top(\mathbf{K} + \sigma^2\mathbf{I})^{-1}\mathbf{y} - \frac{1}{2}\log|\mathbf{K} + \sigma^2\mathbf{I}| - \frac{n}{2}\log(2\pi) \]<p>onde \(\boldsymbol{\theta}\) são os hiperparâmetros do kernel. Esta otimização equilibra o ajuste aos dados com a complexidade do modelo.</p><video style="border:5px solid #ef5350;width:100%;max-width:100%;height:auto" autoplay controls loop muted><source src=https://rodolfoviana.com.br/assets/GP.mp4 type=video/mp4> Your browser does not support HTML5 video.</video><h2 id=processo-gaussiano-variacional-estocastico>Processo Gaussiano Variacional Estocástico</h2><p>Uma limitação importante do GP exato é que ele exige complexidade computacional de \(\mathcal{O}(n^3)\) para treinamento e \(\mathcal{O}(n^2)\) para predição, onde \(n\) é o número de pontos de treinamento. Processo Gaussiano Variacional Estocástico (SVGP) reduz esses custos para \(\mathcal{O}(nm^{2}+m^{3})\) e \(\mathcal{O}(m^{2})\), respectivamente, ao introduzir um conjunto de \(m\) pontos-indutores em \(\mathbf Z={\mathbf z_{j}}_{j=1}^{m}\), com \(m\ll n\)<sup class=footnote-reference id=fr-12-1><a href=#fn-12>12</a></sup> <sup class=footnote-reference id=fr-13-1><a href=#fn-13>13</a></sup> <sup class=footnote-reference id=fr-14-1><a href=#fn-14>14</a></sup> <sup class=footnote-reference id=fr-15-1><a href=#fn-15>15</a></sup>. Estes pontos-indutores são variáveis latentes que resumem as informações do conjunto de treinamento completo.<p>Neste modelo, aproximamos a distribuição a posteriori \(p(\mathbf{f} \mid \mathcal{D})\) por uma distribuição variacional \(q(\mathbf{f})\), isto é,<p>\[ q(\mathbf{f}, \mathbf{u}) = p(\mathbf{f} \mid \mathbf{u})q(\mathbf{u}), \]<p>onde \(\mathbf{f}\) são os valores da função nos pontos de treinamento, \(\mathbf{u}\) são os valores da função nos pontos-indutores, \(p(\mathbf{f} \mid \mathbf{u})\) é a distribuição condicional do GP, e \(q(\mathbf{u})\) é uma distribuição variacional gaussiana com parâmetros a serem otimizados.<p>A otimização é realizada minimizando a divergência Kullback-Leibler entre a distribuição variacional e a distribuição a posteriori verdadeira. A divergão entre duas distribuições contínuas de densidade \(p\) e \(q\) é definida como<p>\[ D_{\mathrm{KL}}(P \mid Q) = \int p(x),\ln!\biggl(\frac{p(x)}{q(x)}\biggr),\mathrm{d}x \]<p>Intuitivamente, \(D_{\mathrm{KL}}(P \mid Q)\) mede o excesso de informação exigido para representar amostras de \(P\) usando um código ótimo baseado em \(Q\) em vez de um código ótimo para \(P\) propriamente dito. Essa divergência é sempre não negativa e zera-se somente quando, para quase todo \(x\), tem-se \(p(x)=q(x)\).<p>A tarefa de minimizar a divergência equivale a maximizar um limite inferior da evidência (ELBO, <em>Evidence Lower Bound</em>).<p>A predição para um novo ponto \(\mathbf{x}_*\) é dada por<p>\[ \begin{aligned} q(f(\mathbf{x}_*)) &= \int p(f(\mathbf{x}_*) \mid \mathbf{u})q(\mathbf{u})d\mathbf{u} \\ &= \mathcal{N}(f(\mathbf{x}_*) \mid \mu_q(\mathbf{x}_*), \sigma_q^2(\mathbf{x}_*)), \end{aligned} \]<p>onde<p>\[ \begin{aligned} \mu_q(\mathbf{x}_*) &= \mathbf{k}_{*z}\mathbf{K}_{zz}^{-1}\boldsymbol{\mu}_u \\ \sigma_q^2(\mathbf{x}_*) &= k(\mathbf{x}_*, \mathbf{x}_*) - \mathbf{k}_{*z}\mathbf{K}_{zz}^{-1}(\mathbf{K}_{zz} - \mathbf{S}_u)\mathbf{K}_{zz}^{-1}\mathbf{k}_{z*} \end{aligned} \]<p>sendo \(\mathbf{k}_{*z}\) o vetor de covariâncias entre \(\mathbf{x}_*\) e os pontos-indutores, \(\mathbf{K}_{zz}\) a matriz de covariância entre os pontos-indutores, e \(\boldsymbol{\mu}_u\) e \(\mathbf{S}_u\) os parâmetros da distribuição variacional \(q(\mathbf{u}) = \mathcal{N}(\boldsymbol{\mu}_u, \mathbf{S}_u)\).<p>Neste trabalho, inspirados nos gargalos de <em>underfitting</em> e instabilidade numérica<sup class=footnote-reference id=fr-16-1><a href=#fn-16>16</a></sup>, utilizamos extensões ao SVGP padrão, tais como seleção adaptativa dos pontos-indutores com base na distribuição dos dados, otimização conjunta dos pontos-indutores e dos hiperparâmetros do kernel, uso de mini-batches durante o treinamento para melhorar a eficiência computacional, e implementação de técnicas de estabilidade numérica, como a decomposição de Cholesky<sup class=footnote-reference id=fr-17-1><a href=#fn-17>17</a></sup> — ou seja, fatoração de uma matriz simétrica e definida positiva \(A\) em \(A = LL^\top\), onde \(L\) é matriz triangular inferior com elementos positivos na diagonal — para o cálculo de inversas de matrizes.<p>Essas melhorias permitem que o SVGP retenha a interpretação probabilística do GP clássico, escale para conjuntos de dados com centenas de milhares de amostras e produza intervalos de predição que combinam validez estatística e largura competitiva.<h2 id=predicao-conformal>Predição Conformal</h2><p>Dada a natureza probabilística dos modelos baseados em GP, os intervalos de predição podem ser derivados diretamente da distribuição a posteriori. Para um nível de confiança \(1-\alpha\), o intervalo de predição para um novo ponto \(\mathbf{x}_*\) é:<p>\[ PI_{1-\alpha}(\mathbf{x}_*) = [\mu(\mathbf{x}_*) - z_{1-\alpha/2} \cdot \sigma(\mathbf{x}_*), \mu(\mathbf{x}_*) + z_{1-\alpha/2} \cdot \sigma(\mathbf{x}_*)] \]<p>onde \(z_{1-\alpha/2}\) é o quantil \(1-\alpha/2\) da distribuição normal padrão.<p>Este intervalo de predição tem uma interpretação bayesiana: assumindo que o modelo e seus hiperparâmetros estão corretos, o intervalo contém o valor verdadeiro com probabilidade \(1-\alpha\). No entanto, na prática, essas suposições podem não ser válidas, levando a intervalos que não atingem a cobertura nominal desejada. A predição conformal<sup class=footnote-reference id=fr-9-2><a href=#fn-9>9</a></sup> <sup class=footnote-reference id=fr-10-2><a href=#fn-10>10</a></sup> é uma abordagem estatística que permite calibrar os intervalos de predição para garantir propriedades teóricas de cobertura, independentemente da distribuição subjacente dos dados ou da adequação do modelo. A ideia central é usar um conjunto de calibração para determinar o quanto os intervalos de predição devem ser contraídos para atingir a cobertura desejada.<p>Neste trabalho, implementamos uma variante da predição conformal conhecida como predição conformal indutiva<sup class=footnote-reference id=fr-18-1><a href=#fn-18>18</a></sup>, que utiliza um conjunto de validação separado para calibração. Além disso, fazemos uso de um escore de não-conformidade natural, dado por<p>\[ s_i = \max\{y_i - l(\mathbf{x}_i), u(\mathbf{x}_i) - y_i, 0\} \]<p>e escolhido por sua simplicidade e interpretabilidade: trata-se do erro absoluto normalizado entre a predição e o valor verdadeiro; mede o quanto o valor verdadeiro está fora do intervalo de predição original.<p>Uma propriedade teórica importante da predição conformal é que, sob a suposição de permutabilidade dos dados, os intervalos de predição conformal garantem uma cobertura marginal de pelo menos \(1-\alpha\) no conjunto de teste<sup class=footnote-reference id=fr-7-2><a href=#fn-7>7</a></sup>. Isso significa que, em média, pelo menos uma fração \(1-\alpha\) dos intervalos conterá os valores verdadeiros, independentemente da adequação do modelo ou da distribuição dos dados.</p><video style="border:5px solid #ef5350;width:100%;max-width:100%;height:auto" autoplay controls loop muted><source src=https://rodolfoviana.com.br/assets/ConformalGPComparison.mp4 type=video/mp4> Your browser does not support HTML5 video.</video><h2 id=execucao-de-testes>Execução de Testes</h2><p>Avaliamos os modelos em três conjuntos de dados públicos amplamente utilizados em problemas de regressão: <em>Combined Cycle Power Plant</em><sup class=footnote-reference id=fr-19-1><a href=#fn-19>19</a></sup> (CCPP), que contém informações de uma usina de ciclo combinado, com o objetivo de prever a potência elétrica líquida; <em>Concrete Compressive Strength</em><sup class=footnote-reference id=fr-20-1><a href=#fn-20>20</a></sup> (Concrete), que contém valores para diferentes misturas de concreto, com o objetivo de prever a resistência à compressão; e <em>Condition Based Maintenance of Naval Propulsion Plants</em><sup class=footnote-reference id=fr-21-1><a href=#fn-21>21</a></sup> (Naval), que contém medições de uma planta de propulsão naval, com o objetivo de prever o coeficiente de decaimento do estado do compressor.<table><thead><tr><th style=text-align:right>Conjuntos<th style=text-align:center>Dimensionalidade<th style=text-align:center>Amostras<th style=text-align:center>Assimetria de \(y\)<th style=text-align:center>Curtose de \(y\)<tbody><tr><td style=text-align:right>CCPP<td style=text-align:center>5<td style=text-align:center>9.568<td style=text-align:center>0,31<td style=text-align:center>1,95<tr><td style=text-align:right>Concrete<td style=text-align:center>9<td style=text-align:center>1.030<td style=text-align:center>0,42<td style=text-align:center>2,69<tr><td style=text-align:right>Naval<td style=text-align:center>18<td style=text-align:center>11.934<td style=text-align:center>0,00<td style=text-align:center>1,80</table><p>Estes conjuntos de dados foram escolhidos por representarem uma variedade de domínios e características, permitindo uma avaliação abrangente dos modelos em diferentes contextos. Para avaliar o desempenho dos intervalos de predição, utilizamos como métricas a cobertura, a largura média dos intervalos de predição (MPIW) e o desempenho.<p>Cobertura é a fração de pontos de teste para os quais o valor verdadeiro está contido no intervalo de predição. Formalmente, para um conjunto de teste com \(n\) pontos, a cobertura é<p>\[ \text{Cobertura} = \frac{1}{n}\sum_{i=1}^{n}\mathbf{1}\{y_i \in PI(\mathbf{x}_i)\} \]<p>onde \(\mathbf{1}\{\cdot\}\) é a função indicadora. Um bom intervalo de predição deve ter uma cobertura próxima ao nível de confiança nominal (\(1-\alpha\)).<p>MPIW, a média da largura dos intervalos de predição, é obtida por meio de<p>\[ \text{MPIW} = \frac{1}{n}\sum_{i=1}^{n}(u(\mathbf{x}_i) - l(\mathbf{x}_i)) \]<p>onde \(l(\mathbf{x}_i)\) e \(u(\mathbf{x}_i)\) são os limites inferior e superior do intervalo de predição para \(\mathbf{x}_i\). Um bom intervalo de predição deve ser o mais estreito possível, condicionado a atingir a cobertura desejada.<p>Para avaliar a precisão das predições pontuais, utilizamos o coeficiente de determinação \(R^2\), que mede a proporção da variância na variável dependente que é previsível a partir das variáveis independentes. Valores mais altos de \(R^2\) indicam melhor desempenho preditivo.<p>Além dessas métricas principais, também calculamos métricas secundárias para uma análise mais detalhada, tais como a diferença entre a cobertura conformada e a cobertura bruta, a diferença entre a largura média do intervalo conformado e a largura média do intervalo bruto, a fração de pontos de teste para os quais o valor verdadeiro está abaixo do limite inferior ou acima do limite superior do intervalo de predição, a razão entre a largura média do intervalo conformado e a largura média do intervalo bruto, e a razão entre a diferença de cobertura e a diferença de largura, que mede a eficiência da calibração conformal.<p>Para garantir a robustez dos resultados, cada conjunto de dados foi treinado utilizando cinco sementes distintas por até 200 épocas, com a possibilidade de parada antecipada no caso de a função de perda não apresentar melhoria por 10 épocas consecutivas, utilizando um delta mínimo de \(1 \times 10^{-6}\) para considerar uma melhoria significativa.<h1 id=resultados>Resultados</h1><p>Os resultados mostram padrões interessantes no comportamento dos modelos. Em primeiro lugar, observamos que os intervalos de predição brutos geralmente têm coberturas significativamente mais altas que o nível nominal de 90%.<table><thead><tr><th rowspan=2>Modelo<th rowspan=2>Conjuntos<th colspan=2>Cobertura (%)<th colspan=2>MPIW<th rowspan=2>R²<tr><th>Bruto<th>Conformal<th>Bruto<th>Conformal<tbody><tr><td rowspan=3>NE-GP<td style=text-align:right>CCPP<td style=text-align:center>99,89<td style=text-align:center>90,13<td style=text-align:center>2,64<td style=text-align:center>0,76<td style=text-align:center>0,941<tr><td style=text-align:right>Concrete<td style=text-align:center>99,03<td style=text-align:center>91,55<td style=text-align:center>2,72<td style=text-align:center>1,47<td style=text-align:center>0,796<tr><td style=text-align:right>Naval<td style=text-align:center>100,00<td style=text-align:center>89,38<td style=text-align:center>2,66<td style=text-align:center>0,83<td style=text-align:center>0,933<tr><td rowspan=3>NE-SVGP<td style=text-align:right>CCPP<td style=text-align:center>90,93<td style=text-align:center>90,13<td style=text-align:center>0,76<td style=text-align:center>0,75<td style=text-align:center>0,945<tr><td style=text-align:right>Concrete<td style=text-align:center>98,83<td style=text-align:center>90,87<td style=text-align:center>2,14<td style=text-align:center>1,18<td style=text-align:center>0,877<tr><td style=text-align:right>Naval<td style=text-align:center>96,65<td style=text-align:center>90,26<td style=text-align:center>0,52<td style=text-align:center>0,39<td style=text-align:center>0,984</table><p>A tabela mostra que, no caso do NE-GP, as coberturas da predição bruta variam de 99,03% a 100,00%, enquanto para o NE-SVGP variam de 90,93% a 98,83%. Isso indica que os intervalos com predição bruta são, de maneira frequente, excessivamente conservadores, resultando em uma cobertura maior que a necessária.<p>Após a aplicação do método conformal, as coberturas são consistentemente ajustadas para valores próximos a 90%, o que é o nível de cobertura nominal desejado. Esse resultado confirma a eficácia da predição conformal em calibrar os intervalos de predição para atingir a cobertura desejada, independentemente do modelo ou do conjunto de dados.<p>Em relação à largura dos intervalos, observamos que, na maioria dos casos, a predição conformal resultou em intervalos mais estreitos. Isso é uma consequência direta da redução da cobertura para o nível nominal de 90%. É importante notar que, idealmente, desejamos intervalos de predição que sejam o mais estreitos possível, condicionado a atingir a cobertura desejada. Quanto ao desempenho, vemos que o NE-SVGP supera significativamente o NE-GP nos conjuntos de dados Naval (0,984 contra 0,933) e Concrete (0,877 contra 0,796), além de apresentar desempenho ligeiramente superior no conjunto CCPP (0,945 contra 0,941).</p><img style="border:5px solid #ef5350;width:100%;max-width:100%;height:auto" src=./combined_models_all_datasets.png><p>A figura, com resultados de execuções na semente 42, ilustra o <em>trade-off</em> entre cobertura e largura dos intervalos. Com NE-GP, em todos os conjuntos de dados, a calibração conformal reduz a cobertura para aproximadamente 90%, enquanto também reduz a largura dos intervalos. O efeito é particularmente pronunciado no conjunto CCPP, onde a largura média é reduzida de 2,64 para 0,76, uma redução de 71,2%, enquanto a cobertura passa de 99,89% para 90,13%.<p>De forma análoga, para NE-SVGP, observamos um padrão semelhante, mas com algumas diferenças notáveis. Em particular, os intervalos brutos já são geralmente mais estreitos em comparação ao modelo NE-GP, e a redução proporcional na largura após a calibração conformal é menor. Por exemplo, no conjunto CCPP, a largura média é reduzida de 0,76 para 0,75, uma redução de apenas 1,3%, enquanto a cobertura passa de 90,93% para 90,13%.<p>Além dessas métricas, os resultados também podem ser avaliados pela porcentagem de erros que, após a predição conformal, se distribuem entre os limites inferior e superior; pela razão entre a largura média do intervalo conformado e a largura média do intervalo bruto, em que valores menores indicam uma redução mais significativa após a aplicação do método conformal; pela redução do excesso de cobertura, que mede a eficiência da predição conformal ao quantificar o ganho obtido por unidade de redução na largura; e pelo erro de calibração, isto é, a diferença absoluta entre a cobertura alcançada e o nível nominal de 90%.<table><thead><tr><th rowspan=2>Modelo<th rowspan=2>Conjunto<th colspan=2>Erros (%)<th rowspan=2>Razão entre Larguras<th rowspan=2>Redução do Excesso de Cobertura<th colspan=2>Erro de Calibração<tr><th>Inferior<th>Superior<th>Bruta<th>Conformal<tbody><tr><td rowspan=3>NE-GP<td style=text-align:right>CCPP<td style=text-align:center>4,22<td style=text-align:center>5,65<td style=text-align:center>0,289<td style=text-align:center>0,052<td style=text-align:center>0,099<td style=text-align:center>0,002<tr><td style=text-align:right>Concrete<td style=text-align:center>4,27<td style=text-align:center>4,17<td style=text-align:center>0,541<td style=text-align:center>0,060<td style=text-align:center>0,090<td style=text-align:center>0,020<tr><td style=text-align:right>Naval<td style=text-align:center>7,63<td style=text-align:center>2,98<td style=text-align:center>0,310<td style=text-align:center>0,058<td style=text-align:center>0,100<td style=text-align:center>0,008<tr><td rowspan=3>NE-SVGP<td style=text-align:right>CCPP<td style=text-align:center>4,25<td style=text-align:center>5,62<td style=text-align:center>0,976<td style=text-align:center>0,339<td style=text-align:center>0,009<td style=text-align:center>0,005<tr><td style=text-align:right>Concrete<td style=text-align:center>3,69<td style=text-align:center>5,44<td style=text-align:center>0,551<td style=text-align:center>0,083<td style=text-align:center>0,088<td style=text-align:center>0,020<tr><td style=text-align:right>Naval<td style=text-align:center>8,35<td style=text-align:center>1,38<td style=text-align:center>0,750<td style=text-align:center>0,553<td style=text-align:center>0,066<td style=text-align:center>0,006</table><p>A tabela revela padrões interessantes na distribuição de erros e na eficácia da calibração conformal. Para o NE-GP, observamos uma distribuição relativamente equilibrada de erros entre os limites inferior e superior nos conjuntos CCPP (4,22% inferior vs. 5,65% superior) e Concrete (4,27% inferior vs. 4,17% superior), enquanto o conjunto Naval apresenta uma assimetria notável com 7,63% de erros no limite inferior contra apenas 2,98% no superior.<p>A razão entre larguras confirma a eficácia da calibração conformal em reduzir significativamente a largura dos intervalos. Para o NE-GP, observamos reduções substanciais: CCPP com razão de 0,289 (redução de 71,1%), Concrete com 0,541 (redução de 45,9%) e Naval com 0,310 (redução de 69,0%). O NE-SVGP apresenta comportamento distinto, com uma redução mais modesta no CCPP (razão de 0,976, apenas 2,4%) mas reduções significativas no Concrete (0,551, redução de 44,9%) e Naval (0,750, redução de 25,0%).<p>O erro de calibração demonstra a superioridade da predição conformal. Para o NE-GP, os erros de calibração brutos variam de 0,090 a 0,100, sendo consistentemente reduzidos para valores próximos a zero após a calibração conformal (0,002 a 0,020). O NE-SVGP já apresenta erros de calibração brutos menores (0,009 a 0,088), mas ainda se beneficia da calibração conformal, alcançando erros finais de 0,005 a 0,020.<h1 id=conclusao>Conclusão</h1><p>Este trabalho investigou em profundidade a integração de processos gaussianos potencializados por redes neurais com a predição conformal como estratégia de calibração de intervalos de predição. Os resultados obtidos em três conjuntos de dados de natureza diversa evidenciam que a conformação fornece ganhos substanciais tanto em confiabilidade estatística quanto em eficiência informacional.<p>Antes da calibração, os intervalos brutos exibiam coberturas muito superiores ao nível nominal de 90%, chegando a 100% no NE-GP para o conjunto Naval e a 99,89% no CCPP. Esse excesso de cobertura, embora pareça desejável à primeira vista, revela intervalos excessivamente largos e, portanto, pouco úteis na prática. A aplicação da predição conformal ajustou sistematicamente a cobertura para valores muito próximos a 90%, confirmando, na prática, as garantias teóricas do método: a cobertura marginal converge ao nível definido independentemente do ajuste do modelo ou da distribuição dos dados.<p>A eficiência desse ajuste refletiu-se diretamente na largura média dos intervalos. No cenário mais expressivo, o CCPP com NE-GP sofreu uma redução de 71,2% na largura após a calibração, de 2,64 para 0,76 unidades, sem comprometer a taxa de acerto exigida. Mesmo no NE-SVGP, onde as larguras iniciais já eram menores devido ao caráter variacional esparso do modelo, observou-se uma diminuição adicional que, embora mais discreta em CCPP (1,3%), alcançou valores consideráveis em Concrete (44,9%) e Naval (25%).<p>Esses achados ressaltam um ponto central: a calibração conformal não apenas corrige a cobertura, mas também tende a remover redundância estatística, comprimindo os intervalos até o limite necessário para preservar o nível de confiança. Em outras palavras, ela transforma incerteza superabundante em informação útil.<p>O contraste entre os dois modelos avaliados fornece observações adicionais. O NE-SVGP, graças ao emprego de pontos-indutores e otimização variacional, obteve desempenho preditivo superior em termos de \(R^2\), chegando a 0,984 no conjunto Naval, e produziu intervalos brutos mais estreitos do que o NE-GP. Ainda assim, não dispensou a calibragem: pequenas violações de cobertura ou assimetrias na distribuição de erros foram corrigidas após a conformação.<p>Para o NE-GP, a dependência da calibração foi ainda mais explícita, dada a tendência do modelo a superestimar incerteza em domínios com alto ruído ou desbalanceamento de características. Portanto, a predição conformal mostrou-se um complemento robusto a ambos os paradigmas: age como uma "segunda linha de defesa" contra defeitos de especificação do modelo e falhas nos pressupostos de ruído homoscedástico ou distribuição independente e identicamente distribuída.<p>Apesar desses êxitos, algumas limitações merecem destaque. Em primeiro lugar, a extensão natural deste trabalho passa pela incorporação explícita de heteroscedasticidade, seja por meio de GPs variacionais locais, seja por modelos híbridos que aprendam a variância condicional da saída. Em segundo lugar, ainda que o SVGP escale melhor que o GP exato, conjuntos com milhões de amostras podem demandar particionamento hierárquico que preservem as garantias da predição conformal.<p>Além disso, a investigação restringiu-se a tarefas de regressão. Como a estrutura teórica do conformal é agnóstica à função de perda, há terreno fértil para explorar classificações ordinais, detecção de anomalias e previsão intervalar em séries temporais, onde pressupostos de permutabilidade precisam ser revisitados.<h1 id=referencias>Referências</h1><section class=footnotes><ol class=footnotes-list><li id=fn-1><p>GAL, Y. <em>Uncertainty in deep learning</em>. Tese (Doutorado) — University of Cambridge, Cambridge, 2016. <a href=#fr-1-1>↩</a></p><li id=fn-2><p>KULESHOV, V.; FENNER, N.; ERMON, S. Accurate uncertainties for deep learning using calibrated regression. In: <em>International Conference on Machine Learning</em>, 35., 2018, p. 2796–2804. <a href=#fr-2-1>↩</a></p><li id=fn-3><p>HÜLLERMEIER, E.; WAEGEMAN, W. Aleatoric and epistemic uncertainty in machine learning: an introduction to concepts and methods. <em>Machine Learning</em>, v. 110, n. 3, p. 457–506, 2021. <a href=#fr-3-1>↩</a></p><li id=fn-4><p>RASMUSSEN, C. E.; WILLIAMS, C. K. I. <em>Gaussian processes for machine learning</em>. Cambridge, MA: MIT Press, 2005. <a href=#fr-4-1>↩</a> <a href=#fr-4-2>↩2</a> <a href=#fr-4-3>↩3</a></p><li id=fn-5><p>MURPHY, K. P. <em>Machine learning: a probabilistic perspective</em>. Cambridge, MA: MIT Press, 2012. <a href=#fr-5-1>↩</a> <a href=#fr-5-2>↩2</a> <a href=#fr-5-3>↩3</a></p><li id=fn-6><p>KENDALL, A.; GAL, Y. What uncertainties do we need in Bayesian deep learning for computer vision? In: <em>Proceedings of the 31st Annual Conference on Neural Information Processing Systems (NIPS'17)</em>, Long Beach, CA, EUA, p. 5580–5590, 2017. <a href=#fr-6-1>↩</a></p><li id=fn-7><p>ANGELOPOULOS, A. N.; BATES, S. A gentle introduction to conformal prediction and distribution-free uncertainty quantification. <em>arXiv preprint arXiv:2107.07511</em>, 2022. <a href=#fr-7-1>↩</a> <a href=#fr-7-2>↩2</a></p><li id=fn-8><p>BALASUBRAMANIAN, V.; HO, S.-S.; VOVK, V. <em>Conformal prediction for reliable machine learning: theory, adaptations and applications</em>. 1. ed. San Francisco: Morgan Kaufmann Publishers Inc., 2014. <a href=#fr-8-1>↩</a></p><li id=fn-9><p>VOVK, V.; GAMMERMAN, A.; SHAFER, G. <em>Algorithmic learning in a random world</em>. New York, NY: Springer, 2005. <a href=#fr-9-1>↩</a> <a href=#fr-9-2>↩2</a></p><li id=fn-10><p>SHAFER, G.; VOVK, V. A tutorial on conformal prediction. <em>The Journal of Machine Learning Research</em>, v. 9, p. 371–421, 2008. <a href=#fr-10-1>↩</a> <a href=#fr-10-2>↩2</a></p><li id=fn-11><p>LEI, J.; G'S ELL, M.; RINALDO, A.; TIBSHIRANI, R. J.; WASSERMAN, L. Distribution-free predictive inference for regression. <em>Journal of the American Statistical Association</em>, v. 113, n. 523, p. 1094–1111, 2018. <a href=#fr-11-1>↩</a></p><li id=fn-12><p>QUINONERO-CANDELA, J.; RASMUSSEN, C. E. A unifying view of sparse approximate Gaussian process regression. <em>Journal of Machine Learning Research</em>, v. 6, n. 65, p. 1939–1959, 2005. <a href=#fr-12-1>↩</a></p><li id=fn-13><p>SNELSON, E.; GHAMRAMANI, Z. Sparse Gaussian processes using pseudo-inputs. In: <em>Advances in Neural Information Processing Systems</em>, v. 18, p. 1257–1264, 2005. MIT Press. <a href=#fr-13-1>↩</a></p><li id=fn-14><p>TITSIAS, M. Variational learning of inducing variables in sparse Gaussian processes. In: <em>Proceedings of the Twelfth International Conference on Artificial Intelligence and Statistics</em>, 5., Clearwater, FL: PMLR, p. 567–574, 2009. <a href=#fr-14-1>↩</a></p><li id=fn-15><p>HENSMAN, J.; FUSI, N.; LAWRENCE, N. D. Gaussian processes for big data. In: <em>Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence</em>, Bellevue, WA; Arlington, VA: AUAI Press, p. 282–290, 2013. <a href=#fr-15-1>↩</a></p><li id=fn-16><p>DEWOLF, N.; DE BAETS, B.; WAEGEMAN, W. Valid prediction intervals for regression problems. <em>Artificial Intelligence Review</em>, v. 56, n. 1, p. 577–613, 2023. <a href=#fr-16-1>↩</a></p><li id=fn-17><p>GOLUB, G. H.; VAN LOAN, C. F. <em>Matrix computations</em>. 4. ed. Baltimore, MD: Johns Hopkins University Press, 2013. <a href=#fr-17-1>↩</a></p><li id=fn-18><p>PAPADOPOULOS, H.; PROEDROU, K.; VOVK, V.; GAMMERMAN, A. Inductive confidence machines for regression. In: <em>Machine Learning: ECML 2002</em>, Berlin; Heidelberg: Springer Berlin Heidelberg, p. 345–356, 2002. <a href=#fr-18-1>↩</a></p><li id=fn-19><p>TFEKCI, P.; KAYA, H. Combined cycle power plant. UCI Machine Learning Repository, 2014. <a href=#fr-19-1>↩</a></p><li id=fn-20><p>YEH, I.-C. Concrete compressive strength. UCI Machine Learning Repository, 1998. <a href=#fr-20-1>↩</a></p><li id=fn-21><p>CORADDU, A.; ONETO, L.; GHIO, A.; SAVIO, S.; ANGIUTA, D.; FIGARI, M. Condition based maintenance of naval propulsion plants. UCI Machine Learning Repository, 2014. <a href=#fr-21-1>↩</a></p></ol></section></section></article></main><footer class=footer><div class=footer-content><div class=footer-left>© 2026 Rodolfo Viana</div><div class=footer-right>Feito com <a href=https://www.getzola.org/ rel=noopener target=_blank>Zola</a>, <a href=https://github.com/not-matthias/apollo rel=noopener target=_blank>Apollo</a></div></div></footer></div>